# Architecture Plan: LLM and MongoDB Integration for AI Role Onboarding

## 1. Overview

This document outlines the architecture for integrating a Large Language Model (Google Generative AI) and MongoDB into the AI Role Onboarding chat feature of the Creator Space application. The primary goal is to transition from a mock-data prototype to a dynamic system where AI Roles are generated by an LLM based on user interaction and persisted in a database.

## 2. Components

### 2.1. Frontend (Next.js/React - `src/app/onboarding/page.tsx`)

*   **Responsibilities:**
    *   Manage the chat UI and user interaction.
    *   Send user messages and conversation history to a backend API route.
    *   Receive LLM text responses and AI Role JSON data from the API.
    *   Display LLM responses in the chat.
    *   Update the sidebar and modal with AI Role data (now sourced from the API/database).
*   **Key Changes:**
    *   Replace mock AI response logic with `fetch` calls to the new API endpoint.
    *   Handle API responses, including potential errors.
    *   Update state management for `createdAiRoles` based on data from the API.

### 2.2. Backend API Route (Next.js - `src/app/api/onboarding/chat/route.ts`)

*   **Responsibilities:**
    *   Accept POST requests from the frontend containing the current user message and conversation context (history).
    *   Securely access the Google AI API Key from environment variables.
    *   Instantiate and configure the Google Generative AI client.
    *   Construct a suitable prompt for the LLM, instructing it to:
        *   Engage in a conversational turn.
        *   Generate an AI Role JSON object based on the conversation. The JSON should adhere to the predefined `AiRole` interface.
    *   Send the prompt to the Google Generative AI API.
    *   Process the LLM's response:
        *   Extract the conversational text part.
        *   Extract and validate the AI Role JSON part.
    *   (In a subsequent step) Connect to MongoDB and save the validated AI Role JSON.
    *   Return the conversational text and the AI Role JSON (or an appropriate error) to the frontend.
*   **Technology:** Next.js API Routes, `@google/generative-ai` SDK.

### 2.3. LLM (Google Generative AI - Gemini)

*   **Responsibilities:**
    *   Understand the user's intent and conversation context.
    *   Generate a natural language response for the chat.
    *   Generate a structured JSON object for the AI Role, following the schema provided in the prompt.
*   **Prompt Engineering:**
    *   The system prompt sent to Gemini will be crucial. It needs to clearly define:
        *   The expected conversational behavior.
        *   The exact JSON schema for the AI Role (`title`, `description`, `systemPromptText`, `category`, `tags`, `version`, `createdAt`, `createdBy`).
        *   Instructions on how to derive the JSON fields from the user's input.
        *   Example of a desired JSON output.

### 2.4. Database (MongoDB with Mongoose)

*   **Responsibilities:**
    *   Store AI Role documents.
    *   Allow for querying and retrieval of AI Roles.
*   **Schema (`AiRoleSchema`):**
    *   A Mongoose schema will be defined to match the `AiRole` interface:
        *   `id` (string, unique - though MongoDB provides `_id`)
        *   `title` (string, required)
        *   `description` (string, required)
        *   `systemPromptText` (string, required)
        *   `category` (string, default: "Custom")
        *   `tags` (array of strings)
        *   `version` (number, default: 1)
        *   `createdAt` (Date, default: Date.now)
        *   `createdBy` (string, e.g., user ID - for now, can be a placeholder like "onboarding_session")
*   **Connection:**
    *   MongoDB connection URI will be stored in environment variables.
    *   A utility function might be used for establishing and managing the database connection.

## 3. Data Flow

1.  User types a message in the onboarding chat UI and sends it.
2.  Frontend (`page.tsx`) captures the message and current conversation history.
3.  Frontend sends a POST request to `/api/onboarding/chat` with the message and history.
4.  API route (`route.ts`) receives the request.
5.  API route constructs a prompt for Gemini, including the user's input and the required JSON output format.
6.  API route sends the prompt to the Google Generative AI API.
7.  Gemini processes the prompt and returns a response containing conversational text and the AI Role JSON.
8.  API route parses the LLM response.
9.  (Future Step) API route validates the AI Role JSON and saves it to MongoDB.
10. API route sends a JSON response back to the frontend, including the LLM's conversational text and the (potentially saved) AI Role data.
11. Frontend receives the API response.
12. Frontend updates the chat display with the LLM's text response.
13. Frontend updates the `createdAiRoles` state with the new AI Role, causing the sidebar and modal to reflect the new data.

## 4. Error Handling

*   **Frontend:**
    *   Handle network errors when calling the API.
    *   Display user-friendly error messages if the API returns an error.
*   **API Route:**
    *   Validate incoming request payloads.
    *   Handle errors from the Google Generative AI API (e.g., API key issues, rate limits, content filtering).
    *   Handle errors during JSON parsing/validation from the LLM response.
    *   Handle errors during database operations (e.g., connection issues, validation errors).
    *   Return appropriate HTTP status codes and error messages.

## 5. Security Considerations

*   **API Keys:** The Google AI API Key must be stored securely as an environment variable on the server-side and never exposed to the frontend.
*   **Database Credentials:** MongoDB connection string (including credentials) must be stored securely as an environment variable.
*   **Input Sanitization/Validation:** While the LLM will process natural language, any data extracted and stored should be validated, especially if it's used in other parts of the application. For the AI Role JSON, ensure it conforms to the expected schema.

## 6. Scalability (Future Considerations)

*   For high traffic, consider optimizing LLM calls (e.g., response streaming).
*   Database indexing for efficient querying of AI Roles.
*   Rate limiting on the API route if necessary.

## 7. Task Breakdown (for GitHub Issues)

*   **Task 1: Setup Backend API Route for Onboarding Chat**
    *   Description: Create the file structure and basic POST handler for `/api/onboarding/chat/route.ts`.
*   **Task 2: Integrate Google Generative AI SDK**
    *   Description: Add the `@google/generative-ai` package. Implement basic client setup and API key handling (via environment variables) in the API route.
*   **Task 3: Develop Initial Prompt for LLM (AI Role Generation)**
    *   Description: Design and implement the initial system prompt to guide Gemini in conversation and AI Role JSON generation.
*   **Task 4: Implement LLM Call and Response Handling in API**
    *   Description: Write the logic in the API route to call the Gemini API, send the prompt, and parse its response (text and JSON).
*   **Task 5: Update Frontend to Call Chat API**
    *   Description: Modify `src/app/onboarding/page.tsx` to replace mock AI logic with `fetch` calls to the `/api/onboarding/chat` endpoint. Update state based on API response.
*   **Task 6: Setup MongoDB Connection and Mongoose Schema**
    *   Description: Add Mongoose. Define the `AiRoleSchema`. Implement MongoDB connection logic (using environment variables for URI).
*   **Task 7: Implement Save AI Role to MongoDB in API**
    *   Description: Add logic to the API route to save the LLM-generated and validated AI Role JSON to the MongoDB database.
*   **Task 8: (Optional) Frontend - Fetch Existing Roles**
    *   Description: If desired for the onboarding, implement logic to fetch and display roles already created by the user in previous sessions.
*   **Task 9: Error Handling and Validation (Full-Stack)**
    *   Description: Implement robust error handling and data validation across the frontend, API route, and during LLM/DB interactions.
*   **Task 10: Testing and Refinement**
    *   Description: Thoroughly test the end-to-end flow, refine prompts, and address any bugs.
